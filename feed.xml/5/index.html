<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
    xmlns:content="http://purl.org/rss/1.0/modules/content/"
    xmlns:wfw="http://wellformedweb.org/CommentAPI/"
    xmlns:dc="http://purl.org/dc/elements/1.1/"
    xmlns:atom="http://www.w3.org/2005/Atom"
    xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
    xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
>
 
<channel>
    <title>Bruno P. Kinoshita</title>
    <atom:link href="/blog/feed.xml" rel="self" type="application/rss+xml" />
    <link>/</link>
    <description></description>
    <lastBuildDate>1508237359.6965277</lastBuildDate>
    <language>en-US</language>
    <generator>PieCrust 2.1.1</generator>
 

<item>
    <title>Using the AWS API with Python</title>
    <pubDate>Oct 04, 2016</pubDate>
    <link>/2016/10/04/using-the-aws-api-with-python</link>
    <dc:creator></dc:creator>
    <description><p>Amazon Web Services provides a series of cloud services. When you access the web interface, most - if not all - of the actions you do there are actually translated into API calls.</p>
<p>They also provide SDK&#8217;s in several programming languages. With these SDK&#8217;s you are able to call the same API used by the web interface. Python has <a href="https://github.com/boto/boto3">boto</a> (or boto3) which lets you to automate several tasks in AWS.</p>
<p>But before you start using the API, you will need to <a href="https://web.archive.org/web/20160818112016/http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html">set up your access key</a>.</p>
<p>It is likely that with time you will have different roles, and may have different permissions with each role. You have to configure your local environment so that you can either use the command line Python utility (installed via <code>pip install awscli</code>) or with boto.</p>
<p>The awscli is a dependency for using boto3. After you install it, you need to run <code>aws configure</code>. It will create the <em>~/.aws/config</em> and <em>~/.aws/credentials</em> files. You can tweak these files to support multiple roles.</p>
<p>I followed the tutorials, but got all sorts of different issues. Then after debugging some locally installed dependencies, in special awscli files, I found that the following settings work for my environment.</p>
<div class="highlight"><pre><span class="c"># File: config</span>
<span class="o">[</span>profile default<span class="o">]</span>
<span class="nv">region</span> <span class="o">=</span> ap-southeast-2

<span class="o">[</span>profile profile1<span class="o">]</span>
<span class="nv">region</span> <span class="o">=</span> ap-southeast-2
<span class="nv">source_profile</span> <span class="o">=</span> default
<span class="nv">role_arn</span> <span class="o">=</span> arn:aws:iam::123:role/Developer

<span class="o">[</span>profile profile2<span class="o">]</span>
<span class="nv">region</span> <span class="o">=</span> ap-southeast-2
<span class="nv">source_profile</span> <span class="o">=</span> default
<span class="nv">role_arn</span> <span class="o">=</span> arn:aws:iam::456:role/Sysops
<span class="nv">mfa_serial</span> <span class="o">=</span> arn:aws:iam::789:mfa/user@domain.blabla
</pre></div>

<p>and</p>
<div class="highlight"><pre><span class="c"># File: credentials</span>
<span class="o">[</span>default<span class="o">]</span>
<span class="nv">aws_access_key_id</span> <span class="o">=</span> YOU_KEY_ID
<span class="nv">aws_secret_access_key</span> <span class="o">=</span> YOUR_SECRET
</pre></div>

<p>And once it is done you can, for example, confirm it is working with some S3 commands in Python.</p>
<div class="highlight"><pre><span class="c">#!/usr/bin/env python3</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">boto3</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">profile_name</span><span class="o">=</span><span class="s">&#39;profile2&#39;</span><span class="p">)</span>
<span class="n">s3</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">&#39;s3&#39;</span><span class="p">)</span>

<span class="n">found</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">name</span> <span class="o">=</span> <span class="s">&#39;mysuperduperbucket&#39;</span>

<span class="k">for</span> <span class="n">bucket</span> <span class="ow">in</span> <span class="n">s3</span><span class="o">.</span><span class="n">buckets</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">bucket</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">found</span> <span class="o">=</span> <span class="bp">True</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">found</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Creating bucket...&quot;</span><span class="p">)</span>
    <span class="n">s3</span><span class="o">.</span><span class="n">create_bucket</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

<span class="n">file_location</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">__file__</span><span class="p">))</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s">&#39;samplefile.txt&#39;</span>
<span class="n">s3</span><span class="o">.</span><span class="n">meta</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">upload_file</span><span class="p">(</span><span class="n">Filename</span><span class="o">=</span><span class="n">file_location</span><span class="p">,</span> <span class="n">Bucket</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">Key</span><span class="o">=</span><span class="s">&#39;book.txt&#39;</span><span class="p">)</span>
</pre></div>

<p>The AWS files in this example are using MFA too, the multi-factor authentication. So the first time you run this code you may be asked to generate a token, which will be cached for a short time.</p>
<p>That&#8217;s it for today.</p>
<p>Happy hacking!</p></description>
</item>

<item>
    <title>Best place to find science fiction books in New Zealand</title>
    <pubDate>Oct 02, 2016</pubDate>
    <link>/2016/10/02/best-place-to-find-science-fiction-books-in-new-zealand</link>
    <dc:creator></dc:creator>
    <description><p>Since I moved to New Zealand it has been hard to find good science fiction sections in the local book stores. I really miss the Livraria Cultura at Avenida Paulista, or the Saraiva Megastores. Whitcoulls and Paper Plus do a good job, but they have very few series, only recent releases, and you do not feel that cool environment while you browse the books.</p>
<p>I found that small secondhand bookstores are the best places to find good books - not only science fiction - in New Zealand. Devonport has one, near the waterfront. Auckland has Jason books too, right in the CBD. Wellington, Dunedin and Queenstown too (the Queenstown one is on the second level in a small mall, you have to check it out!).</p>
<p>But last week I remembered my wife telling me about this web site, <a href="https://www.hardtofind.co.nz/">https://www.hardtofind.co.nz/</a>. I found several books from <a href="http://kinoshita.eti.br/books/#my-wish-list">my Wish List</a> there, and also other Stephen King books recommended by the bookstore clerk from Queenstown.</p>
<p><img class="ui centered image" src="/2016/10/02/best-place-to-find-science-fiction-books-in-new-zealand/books-hard-to-find-store.jpg" alt="Books from Hard To Find bookstore" /></p>
<p>If you are into science fiction, Asimov, Neal Stephenson, Peter H. Hamilton, Piers Anthony, Arthur C. Clarke, Stephen King, etc, I am sure you will enjoy going to the Hard To Find store in Onehunga. It is near the Dress Smart. So during week if you stop by Dress Smart, you can hop on their free bus from the city centre and later enjoy checking out the store too.</p>
<p>It is a two story house, with lots of rooms, with science fiction, New Zealand, maritime sports, arts, poetry, health, etc.</p>
<p>Happy reading!</p></description>
</item>

<item>
    <title>Performance problems in Jenkins TAP Plug-in &mdash; part 1</title>
    <pubDate>Sep 03, 2016</pubDate>
    <link>/2016/09/03/performance-problems-in-jenkins-tap-plugin-part-1</link>
    <dc:creator></dc:creator>
    <description><p><a href="https://issues.jenkins-ci.org/browse/JENKINS-17887">JENKINS-17887</a> reports performance problems in the <a href="https://wiki.jenkins-ci.org/display/JENKINS/TAP+Plugin">Jenkins TAP Plug-in</a>. It also lists a series of suggestions on how to improve the Jenkins TAP Plug-in performance. On this initial post, we will get a general idea of how the plug-in performs for large projects.</p>
<p><a href="http://bioperl.org/">BioPerl</a> has over 21K tests. That should be enough for giving an initial idea of CPU, memory and disk usage for the plug-in.</p>
<div class="highlight"><pre>git clone https://github.com/bioperl/bioperl-live.git
<span class="nb">cd </span>bioperl-live
sudo cpanm  -vv --installdeps --notest .
sudo cpanm Set::Scalar Graph::Directed XML::LibXML XML::SAX <span class="se">\</span>
    SVG XML::Parser::PerlSAX Convert::Binary::C XML::SAX::Writer <span class="se">\</span>
    XML::DOM::XPath Spreadsheet::ParseExcel XML::SAX::Writer <span class="se">\</span>
    XML::DOM HTML::TableExtract XML::Simple Test::Pod DBI
prove -r t/ -a tests.tar.gz

All tests successful.
<span class="nv">Files</span><span class="o">=</span>325, <span class="nv">Tests</span><span class="o">=</span>21095, <span class="m">94</span> wallclock secs <span class="o">(</span> 2.47 usr  0.55 sys + 88.29 cusr  3.85 <span class="nv">csys</span> <span class="o">=</span> 95.16 CPU<span class="o">)</span>
Result: PASS
</pre></div>

<p>When the test results are parsed, the plug-in also copies TAP files over to the master, in a folder called <em>tap-master-files</em>.</p>
<p>The BioPerl tests are not really big, just <strong>1.7M</strong>. It gets doubled as there will be the workspace copy, and the tap-master-files directory copy, so <strong>3.4M</strong>.</p>
<p>But several objects get created in memory, and persisted into the build.xml job file. BioPerl generates a build.xml file with <strong>11M</strong>. So <strong>less than 15M</strong>. But the build.xml contains objects that are read via XStream by Jenkins and into the memory.</p>
<p>The build page with the graph, and the other two test result pages are rendering in more than 10 seconds in my computer. But the CPU load is OK, so a closer look at the memory use would probably be more interesting.</p>
<p><img class="ui centered image" src="/2016/09/03/performance-problems-in-jenkins-tap-plugin-part-1/JENKINS-17887-yourkit1.png" alt="JENKINS-17887 YourKit profiler" /></p>
<p>The image shows one of the screens in YourKit profiler, where it is possible to see that <strong>org.tap4j.plugin.model.TapTestResultResult</strong> has over 6 million objects.</p>
<p>One build.xml for the BioPerl project gets over 80K entries for the TestResult object.</p>
<div class="highlight"><pre>grep <span class="s2">&quot;org.tap4j.model.TestResult&quot;</span> builds/1/build.xml -o <span class="p">|</span> wc -l
84522
</pre></div>

<p>This happens because each TAP file may contain multiple test results (lines with test results). Each of these test results gets turned into a Java object and loaded by the plug-in. So when loading the test result pages, Jenkins needs to wait until all these objects have been parsed, deserialized and read into the memory.</p>
<p>The next post will continue on code improvements, and another benchmark.</p>
<p>Happy profiling!</p></description>
</item>

<item>
    <title>Revamping Frege logo &mdash; part 2</title>
    <pubDate>Aug 24, 2016</pubDate>
    <link>/2016/08/24/revamping-frege-logo-part-2</link>
    <dc:creator></dc:creator>
    <description><p>Last time I used Blender was around 2007 I think, in University. But the bad weather in
Auckland gives me plenty of time to have fun checking out Blender again :-)</p>
<p>Followed the following tutorials:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=GeKhH1aaXuM">How to create a 3D Logo in Blender</a></li>
<li><a href="https://www.youtube.com/watch?v=LArn4TFNnmk">Blender Tutorial Spinning Logo</a></li>
</ul>
<p>Here are the work in progress, created only with the b&eacute;zier curve.</p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Frege_logo_flat_colours.png" alt="Frege updated logo" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-14_20-19-35.png" alt="Frege 3D #1" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-14_20-39-46.png" alt="Frege 3D #2" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-14_20-41-15.png" alt="Frege 3D #3" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-14_20-41-34.png" alt="Frege 3D #4" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-14_20-57-02.png" alt="Frege 3D #5" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-23_22-07-54.png" alt="Frege 3D #6" /></p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Screenshot_2016-08-23_22-30-24.png" alt="Frege 3D #7" /></p>
<p>Here&#8217;s the result after the mesh was created, and some material applied.</p>
<p><img class="ui centered large image" src="/2016/08/24/revamping-frege-logo-part-2/Frege3d1.png" alt="Frege 3D #8" /></p>
<p>Then using a plane as background, replacing the lamp by a sun, and tweaking a few parameters.</p>
<p><img class="ui centered image" src="/2016/08/24/revamping-frege-logo-part-2/Frege3d2.png" alt="Frege 3D #9" /></p>
<p>And finally playing with animation. Not sure if there was a time line and animation controls in
Blender the last time I used it, but the controls are not really complex.</p>
<p>I had to combine both meshes into a single object, in order to add a bone and rotate it. That
is why the logo got back to a single material. The angle of the camera could probably do with
some tweaking as well.</p>
<p><img class="ui centered image" src="/2016/08/24/revamping-frege-logo-part-2/ezgif.com-resize.gif" alt="Frege 3D #10" /></p>
<p>But it was my very first time animating in Blender. Some day if I get access to one of those
3D printers, I will check what are the requirements for printing this logo.</p>
<p>Blender models can be downloaded <a href="https://github.com/kinow/kinoshita.eti.br/tree/master/posts/2016-08-24_revamping-frege-logo-part-2-assets">here</a>.</p>
<p>Now back to programming :-)</p></description>
</item>

<item>
    <title>Revamping Frege logo</title>
    <pubDate>Aug 16, 2016</pubDate>
    <link>/2016/08/16/revamping-frege-logo</link>
    <dc:creator></dc:creator>
    <description><p>For a while I had been wanting to try adding a flat colour to the Frege
logo. This weekend had some bit of spare time, and here is the result.</p>
<p>Submitted to the project as <a href="https://github.com/Frege/frege/pull/299/files">pull request #299</a>.</p>
<p>Current logo.</p>
<p><img class="ui centered large image" src="/2016/08/16/revamping-frege-logo/Frege_logo.png" alt="Frege current logo" /></p>
<p>And the updated logo.</p>
<p><img class="ui centered large image" src="/2016/08/16/revamping-frege-logo/Frege_logo_flat_colours.png" alt="Frege updated logo" /></p>
<p>The colour used was Flamingo (#EF4836), found in <a href="http://www.flatuicolorpicker.com/">Flat UI Color Picker</a>.</p>
<p>Perhaps not exactly revamping, since all I did was just change a colour. There were
adjustments to the b&eacute;zier curves as well, to better align them, but I updated both
logos, not just the new one :-)</p></description>
</item>

<item>
    <title>Reading notes about DRMAA v2</title>
    <pubDate>Jul 20, 2016</pubDate>
    <link>/2016/07/20/reading-notes-about-drmaa-v2</link>
    <dc:creator></dc:creator>
    <description><p>The DRMAA v2 specification draft is ready to be published, and is in <a href="https://redmine.ogf.org/boards/36/topics/494">public
comment</a> until 31st July this year.
I used DRMAA v1 to integrate Jenkins and PBS some time ago, but it was not a
very elegant solution.</p>
<p>And in the end integrating other grid computing implementations like SGE would
not be very simple.</p>
<p>This post contains my reading notes for DRMAA v2, and a short analysis of how
this new specification could be used in a new tentative to integrate
Jenkins and several grid computing implementations in a single plug-in.</p>
</description>
</item>

<item>
    <title>Reasons for having pt and pt-BR in a software</title>
    <pubDate>Jul 17, 2016</pubDate>
    <link>/2016/07/17/reasons-for-having-pt-and-ptbr-in-a-software</link>
    <dc:creator></dc:creator>
    <description><p>Some time ago I found some spare time to work on a different Open Source project:
<a href="http://skosmos.org/">SKOSMOS</a>. SKOSMOS is a web based SKOS browser and publishing
tool, used to create vocabularies using the SKOS ontology.</p>
<p>I decided to help with translation, but there was no Brazilian Portuguese option,
only Portuguese. I used a few arguments to suggest that having Brazilian Portuguese
would be a good thing.</p>
<p>Another Open Source project that I use in a side project is
<a href="https://www.languagetool.org/">LanguageTool</a>. LanguageTool is used for
proof-reading, and uses rules to find spelling and grammar errors.</p>
<p>Today I saw a message in the LanguageTool mailing list discussing whether having a Brazilian
Portuguese page would make sense, or if it would be better to have just Portuguese, and then
add rules for special cases.</p>
</description>
</item>

<item>
    <title>Processing Vaisala Radiosonde data with Python, and creating GRUAN-like NetCDF files</title>
    <pubDate>Jul 12, 2016</pubDate>
    <link>/2016/07/12/processing-vaisala-radiosonde-data-with-python-and-creating-gruan-like-netcdf-files</link>
    <dc:creator></dc:creator>
    <description><p>One of my last projects involved parsing a few GB&#8217;s of data that was in a certain binary format,
and convert it into NetCDF files. In this post I will describe what was done, what I learned about radiosonde,
<a href="http://www.dwd.de/EN/research/international_programme/gruan/home.html">GRUAN</a> and other geek stuff. Ready?</p>
<h3>Vaisala Radiosonde data</h3>
<p>When I was told the data was in some binary format, I thought it would be similar to
parsing a flat file. That this would contain a fixed length entry, with the same
kind of item repeated multiple times.</p>
<p>Well, not exactly.</p>
<p>The files had been generated by an instrument made by <a href="http://www.vaisala.com">Vaisala</a>, a Finnish company. This
instrument is called a <strong>radiosonde</strong>. It is an instrument about the size of an old
mobile phone, that is launched with a balloon into the atmosphere.</p>
<p>I was lucky to be given the chance to release one of these balloons carrying a newer
version of this equipment.</p>
<p><img class="ui centered large bordered image" src="/2016/07/12/processing-vaisala-radiosonde-data-with-python-and-creating-gruan-like-netcdf-files/balloon-launch.jpg" alt="Radiosonde balloon launch" /></p>
<p>The balloon can carry equipments for measuring different things, like air pressure,
altitude, temperature, latitude, longitude, relative humidity, among others. Equipments
like the radiosonde send the data back to a ground-level station via radio,
normally in a short and constant interval.</p>
</description>
</item>

<item>
    <title>Drawing sketch: Blue Hair</title>
    <pubDate>May 16, 2016</pubDate>
    <link>/2016/05/16/drawing-sketch-bluehair</link>
    <dc:creator></dc:creator>
    <description><div class='row'>
<div class="ui container" style='text-align: center;'>
<figure>
<a href="/2016/05/16/drawing-sketch-bluehair/bluehair.jpg" rel="prettyPhoto" class="thumbnail" title="Blue Hair">
<img class="ui fluid image" src="/2016/05/16/drawing-sketch-bluehair/bluehair.jpg" alt="Blue Hair" />
</a>
<figcaption>Blue Hair</figcaption>
</figure>
</div>
</div>

<p>For <a href="https://www.reddit.com/r/redditgetsdrawn/comments/4jakp0/someone_told_me_to_post_here_with_my_new_hair/">redditgetsdrawn</a></p></description>
</item>

<item>
    <title>Some Linux commands I used this week</title>
    <pubDate>May 06, 2016</pubDate>
    <link>/2016/05/06/some-linux-commands-i-used-this-week</link>
    <dc:creator></dc:creator>
    <description><p>These are some commands I used on Linux servers this week. Adding them here in case someone else
find them interesting, and also due to my bad memory :-)</p>
<h2>Listing latest installed packages in SLES</h2>
<div class="highlight"><pre>rpm -qa --last
</pre></div>

<p>This will display the last packages installed. Useful when there are packages being updated, and you
need to confirm what changed, and when.</p>
<h2>Listing packages in SLES and origin repository</h2>
<div class="highlight"><pre>rpm -qa --qf <span class="s1">&#39;%-30{DISTRIBUTION} %{NAME}\n&#39;</span><span class="p">|</span> sort
</pre></div>

<p>The output will have two columns. The first containing the repository name, and the second column with
the package name. For example.</p>
<div class="highlight"><pre>devel:languages:R:base / SLE_11_SP2 R-base
devel:languages:R:base / SLE_11_SP2 R-base-devel
home:flacco:sles / SLE_11_SP3 php53-phar
home:happenpappen / SLE_11_SP2 nodejs
</pre></div>

<h2>Grep for content in XML tags</h2>
<p>Be it for web services, or for finding things in Jenkins XML files. Being able to grep the tag attribute
or tag name might be useful. Look at the following example that uses the 
<a href="https://msdn.microsoft.com/en-us/library/ms762271%28v=vs.85%29.aspx">books XML provided by Microsoft for testing</a>.</p>
<div class="highlight"><pre>grep -oP <span class="s2">&quot;(?&lt;=&lt;genre&gt;).*?(?=&lt;/genre&gt;)&quot;</span> books.xml <span class="p">|</span> sort <span class="p">|</span> uniq
</pre></div>

<p>Which will outputs the following.</p>
<div class="highlight"><pre>Computer
Fantasy
Horror
Romance
Science Fiction
</pre></div>

<h2>Find Python site packages directory</h2>
<p>Sometimes you have Anaconda, but also the system installation, and maybe even other Python distributions.
Knowing where Python is looking for site packages can be helpful to confirm the package exists, and also
to inspect its sources.</p>
<div class="highlight"><pre>python -c <span class="s2">&quot;from distutils.sysconfig import get_python_lib; print(get_python_lib())&quot;</span>
</pre></div>

<p>An example of the output of the script.</p>
<div class="highlight"><pre>/usr/lib/python2.7/dist-packages
</pre></div>

<h2>Force no-cache via curl for a list of files</h2>
<p>Useful when you have a proxy like squid caching some requests from an application and you
want to flush the cache and get the latest content (which will be cached again, but then
you can fix it once confirmed).</p>
<div class="highlight"><pre>curl --silent -H <span class="s1">&#39;Cache-Control: no-cache&#39;</span> http://systemcachingvalues.local/somedoc.html
</pre></div>

<h2>Find to which servers a Linux process is talking to</h2>
<p>You have to find the pid of the process that you would like to investigate (e.g. 6364) and have
<a href="http://linux.die.net/man/1/strace">strace</a> installed.</p>
<div class="highlight"><pre>strace -p <span class="m">6364</span> -f -e <span class="nv">trace</span><span class="o">=</span>network -o output.txt
</pre></div>

<p>The command above creates output.txt with the trace information. Then you can grep for
the IP addresses with the following regex.</p>
<div class="highlight"><pre>grep -E -o <span class="s2">&quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot;</span> output.txt
</pre></div>

<p>Which will output something similar to the following example.</p>
<div class="highlight"><pre>127.0.1.1
127.0.1.1
127.0.1.1
192.168.20.4
10.10.0.12
...
</pre></div>

<p>And finally, you can call dig to get the server name, and also remove duplicates.</p>
<div class="highlight"><pre>grep -E -o <span class="s2">&quot;(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)&quot;</span> output.txt <span class="p">|</span> xargs -l dig +noall +answer +nocmd -x <span class="p">|</span> awk <span class="s1">&#39;{ print $5}&#39;</span> <span class="p">|</span> sort <span class="p">|</span> uniq
</pre></div>

<p>Which gives you the following.</p>
<div class="highlight"><pre>ec2-52-13-43-205.compute-1.amazonaws.com.
ec2-52-32-244-147.compute-1.amazonaws.com.
ec2-52-44-11-85.compute-1.amazonaws.com.
ec2-52-55-36-20.us-west-2.compute.amazonaws.com.
ec2-52-11-19-24.us-west-2.compute.amazonaws.com.
ec2-52-2-21-13.compute-1.amazonaws.com.
ec2-54-33-249-49.us-west-2.compute.amazonaws.com.
ec2-54-180-165-17.us-west-2.compute.amazonaws.com.
ec2-54-2-177-91.compute-1.amazonaws.com.
ec2-54-8-163-15.compute-1.amazonaws.com.
syd11s01-in-f124.1e110.net.
syd11s02-in-f5.1e110.net.
syd12s02-in-f3.1e110.net.
...
</pre></div>

<p>That&#8217;s all for today.</p>
<p>Happy hacking!</p></description>
</item>

</channel>
</rss>